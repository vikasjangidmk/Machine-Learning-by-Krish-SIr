{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "\n",
    "Stemming is a crucial technique in natural language processing (NLP) that reduces words to their base or root form. By transforming different forms of a word into a common base, stemming simplifies the analysis of text data, making it easier to process and understand.\n",
    "\n",
    "## Definition\n",
    "\n",
    "Stemming refers to the process of cutting off the ends of words to obtain their root form. The resulting stem may not be a valid word itself but serves as a representative of all the variations of that word. For example, the words \"running,\" \"runner,\" \"ran,\" and \"runs\" may all be reduced to \"run.\"\n",
    "\n",
    "## Importance of Stemming\n",
    "\n",
    "- **Dimensionality Reduction**: Stemming reduces the number of unique tokens in a dataset, leading to lower complexity and faster processing.\n",
    "- **Improved Search Functionality**: In search engines and information retrieval systems, stemming helps match different forms of a word, improving search accuracy.\n",
    "- **Enhanced Model Performance**: In text classification and clustering tasks, stemming allows models to focus on the core meaning of words, often leading to better performance.\n",
    "- **Standardization**: Stemming standardizes various inflected forms of a word, making it easier to analyze and interpret textual data.\n",
    "\n",
    "## Types of Stemming Algorithms\n",
    "\n",
    "### 1. Porter Stemmer\n",
    "\n",
    "- **Description**: Developed by Martin Porter in 1980, this is one of the most widely used stemming algorithms. It employs a series of rules and suffix stripping methods to iteratively reduce words.\n",
    "- **Phases**: The algorithm consists of several phases, applying specific rules to remove suffixes.\n",
    "- **Example**: \n",
    "  - Input: \"running\" \n",
    "  - Output: \"run\"\n",
    "- **Implementation**:\n",
    "    ```python\n",
    "    from nltk.stem import PorterStemmer\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    print(ps.stem(\"running\"))  # Output: 'run'\n",
    "    ```\n",
    "\n",
    "### 2. Lancaster Stemmer\n",
    "\n",
    "- **Description**: This is a more aggressive stemming algorithm that applies a larger set of rules. While faster than the Porter Stemmer, it can lead to overstemming.\n",
    "- **Example**: \n",
    "  - Input: \"better\"\n",
    "  - Output: \"better\" (may not stem as aggressively)\n",
    "- **Implementation**:\n",
    "    ```python\n",
    "    from nltk.stem import LancasterStemmer\n",
    "\n",
    "    ls = LancasterStemmer()\n",
    "    print(ls.stem(\"better\"))  # Output: 'better'\n",
    "    ```\n",
    "\n",
    "### 3. Snowball Stemmer\n",
    "\n",
    "- **Description**: Also known as the Porter2 Stemmer, this algorithm is an improved version of the Porter Stemmer, supporting multiple languages and offering better stemming quality.\n",
    "- **Example**: \n",
    "  - Input: \"happiness\"\n",
    "  - Output: \"happy\"\n",
    "- **Implementation**:\n",
    "    ```python\n",
    "    from nltk.stem import SnowballStemmer\n",
    "\n",
    "    ss = SnowballStemmer(\"english\")\n",
    "    print(ss.stem(\"happiness\"))  # Output: 'happy'\n",
    "    ```\n",
    "\n",
    "### 4. Krovetz Stemmer\n",
    "\n",
    "- **Description**: This is a hybrid stemming approach that combines stemming and lemmatization. It attempts to find the stem of the word, and if that doesnâ€™t yield a valid word, it resorts to lemmatization.\n",
    "- **Example**: \n",
    "  - Input: \"running\"\n",
    "  - Output: \"run\"\n",
    "- **Implementation**:\n",
    "    ```python\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    print(lemmatizer.lemmatize(\"running\", pos='v'))  # Output: 'run'\n",
    "    ```\n",
    "\n",
    "### 5. RegexpStemmer\n",
    "\n",
    "- **Description**: The `RegexpStemmer` class allows for stemming based on regular expressions. It applies specified regex patterns to remove affixes from words. This method gives users the flexibility to define their stemming rules through regex, making it suitable for specific use cases where standard stemming might not be effective.\n",
    "- **Example**: \n",
    "  - Input: \"running\", using a regex pattern to remove \"ing\"\n",
    "  - Output: \"run\"\n",
    "- **Implementation**:\n",
    "    ```python\n",
    "    from nltk.stem import RegexpStemmer\n",
    "\n",
    "    # Define a regex pattern to remove the suffix \"ing\"\n",
    "    regex_stemmer = RegexpStemmer('ing$')\n",
    "\n",
    "    print(regex_stemmer.stem(\"running\"))  # Output: 'run'\n",
    "    print(regex_stemmer.stem(\"runningly\"))  # Output: 'runningly'\n",
    "    ```\n",
    "\n",
    "## Applications of Stemming\n",
    "\n",
    "- **Information Retrieval**: Enhances the effectiveness of search engines by matching various forms of search queries to their stems.\n",
    "- **Text Classification**: Improves the performance of machine learning models by focusing on the root meaning of words instead of their specific forms.\n",
    "- **Sentiment Analysis**: Assists in analyzing sentiment in text by reducing words to their stems, allowing models to capture the overall sentiment more effectively.\n",
    "- **Topic Modeling and Clustering**: Aids in identifying topics within a dataset by reducing word variations, leading to more coherent clusters.\n",
    "\n",
    "## Advantages of Stemming\n",
    "\n",
    "- **Efficiency**: Reduces the size of the dataset, allowing for faster processing and analysis.\n",
    "- **Simplicity**: Simplifies text by standardizing words, making it easier to perform operations like counting word occurrences.\n",
    "- **Versatility**: Works well across various NLP applications, from search engines to sentiment analysis.\n",
    "\n",
    "## Disadvantages of Stemming\n",
    "\n",
    "- **Overstemming**: This occurs when different words with distinct meanings are reduced to the same stem, potentially leading to loss of important information.\n",
    "- **Loss of Meaning**: The stem produced may not be a meaningful word, which can confuse readers or result in loss of context.\n",
    "- **Language Limitations**: Stemming algorithms are often language-specific, and their effectiveness may vary across languages.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Stemming Algorithms\n",
    "\n",
    "| **Stemming Algorithm** | **Description**                                        | **Advantages**                                             | **Disadvantages**                                            | **Best Use Cases**                                   |\n",
    "|------------------------|--------------------------------------------------------|-----------------------------------------------------------|-----------------------------------------------------------|-----------------------------------------------------|\n",
    "| **Porter Stemmer**     | A widely used stemming algorithm with a series of rules for suffix stripping. | Simple and effective for English text.                    | May lead to overstemming; not as accurate for all words.  | General text analysis, search engines.              |\n",
    "| **Lancaster Stemmer**  | An aggressive stemming algorithm that applies a larger set of rules.      | Fast and easy to implement.                               | Can be overly aggressive; may produce non-words.          | Situations where speed is a priority over accuracy.  |\n",
    "| **Snowball Stemmer**   | Improved version of the Porter Stemmer supporting multiple languages.     | More accurate and supports multiple languages.            | Slightly more complex to implement than Porter Stemmer.    | Multi-language applications and nuanced text analysis. |\n",
    "| **Krovetz Stemmer**    | Hybrid approach combining stemming and lemmatization.                    | Balances between stemming and lemmatization for accuracy. | More computationally intensive; requires a dictionary.     | Tasks requiring precise meaning, such as sentiment analysis. |\n",
    "| **RegexpStemmer**      | Uses regular expressions to define custom stemming rules.                | Highly flexible; users can define specific stemming patterns. | Requires regex knowledge; less intuitive for standard usage.| Custom applications where specific rules are needed. |\n",
    "\n",
    "## Key Points of Comparison\n",
    "\n",
    "- **Accuracy**: The Snowball and Krovetz stemmers tend to offer better accuracy, while the Lancaster stemmer may be more aggressive and less precise.\n",
    "- **Flexibility**: The RegexpStemmer stands out for its flexibility, allowing users to specify exact patterns for stemming based on their needs.\n",
    "- **Speed**: The Lancaster stemmer is typically faster than the others, but this speed can come at the cost of accuracy.\n",
    "- **Language Support**: The Snowball stemmer is the best choice for applications requiring support for multiple languages, whereas the Porter and Lancaster stemmers primarily focus on English.\n",
    "- **Complexity**: The Krovetz and Regexp stemmers may require additional knowledge (of dictionaries and regex, respectively), which can increase implementation complexity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Stemming** \n",
    "\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification Problem\n",
    "## Comments of product is a positive review or negative review\n",
    "## Reviews----> eating, eat,eaten [going,gone,goes]--->go\n",
    "\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eating', 'eats', 'eaten', 'writing', 'writes', 'programming', 'programs', 'history', 'finally', 'finalized']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PorterStemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---------->eat\n",
      "eats---------->eat\n",
      "eaten---------->eaten\n",
      "writing---------->write\n",
      "writes---------->write\n",
      "programming---------->program\n",
      "programs---------->program\n",
      "history---------->histori\n",
      "finally---------->final\n",
      "finalized---------->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---------->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('Congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('sitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RegexpStemmer class**\n",
    "\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boxe'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('boxes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Snowball Stemmer**\n",
    "It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------------->eat\n",
      "eats------------->eat\n",
      "eaten------------->eaten\n",
      "writing------------->write\n",
      "writes------------->write\n",
      "programming------------->program\n",
      "programs------------->program\n",
      "history------------->histori\n",
      "finally------------->final\n",
      "finalized------------->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"------------->\"+snowball.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\") , stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem(\"fairly\") , snowball.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
